{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 网络爬虫理论基础\n",
    "\n",
    "\n",
    "内容导航：\n",
    "\n",
    "1. 网络爬虫的基本概念\n",
    "\n",
    "2. 网络爬虫的用途\n",
    "\n",
    "3. 网络爬虫实现原理与技术"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 网络爬虫的基本概念\n",
    "\n",
    "### 网络爬虫初识\n",
    "\n",
    "网络爬虫（Crawler）又称网络蜘蛛（Spider），网络蚂蚁（Ant）和网络机器人（Robot），可以按照事先制定的规则（爬虫算法）自动地浏览并获取网页信息的计算机程序。\n",
    "\n",
    "爬虫是搜索引擎的核心组件，这种爬虫称为通用爬虫，目的是尽可能多地爬取网页。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 为何要学习爬虫\n",
    "\n",
    "1. 数据采集，为数据分析提供原材料\n",
    "2. 私人定制搜索引擎\n",
    "3. 理解爬虫原理，更好地进行搜索引擎优化（SEO）\n",
    "4. 就业需求旺，薪酬高"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 网络爬虫的组成\n",
    "\n",
    "网络爬虫由**控制节点**、**爬虫节点**和**资源库**构成：\n",
    "\n",
    "* **控制节点**，分配任务，调度协调\n",
    "* **爬虫节点**，采集（下载网页）加工（文本处理），存储入库\n",
    "* **资源库**，存放采集结果和辅助加工处理的资源仓库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网络爬虫的类型\n",
    "\n",
    "网络爬虫按照实现技术和结构可分为：\n",
    "\n",
    "* **通用网络爬虫（General Purposed Web Crawler）**：即全网爬虫，爬取海量数据，大型搜索引擎的核心。主要由***初始（种子）URL集合、URL队列、页面爬行模块、页面分析模块、页面数据库、链接过滤模块***等构成。其爬行策略主要有***深度优先（DF）***和***广度优先（BF）***策略。\n",
    "* **聚焦网络爬虫（Focused Web Crawler）**：即主题网络爬虫，按照预先定义好的主题*有选择*地进行网页爬取的一种爬虫。主要由***初始（种子）URL集合、URL队列、页面爬行模块、页面分析模块、页面数据库、链接过滤模块、内容评价模块、链接评价模块***等构成。其爬行策略主要有四种：基于***内容评价***的爬行策略、基于***链接评价***的爬行策略、基于***增强学习***的爬行策略和基于***语境图***的爬行策略。\n",
    "* **增量式网络爬虫（Incremental Web Crawler）**：只爬取内容发生变化或新网页的爬虫，即只对变化感兴趣的爬虫。\n",
    "* **深层网络爬虫（Deep Web Crawler）**：可以爬取深层页面的爬虫。所谓深层页面是指隐藏于表单之后，不能通过静态链接直接获取，需要提交一定关键词（填写表单）之后才能获取的到的页面。主要由***初始（种子）URL列表、LVS列表（用来填充表单的标签数值集）、爬行控制器、解析器、LVS控制器、表单分析器、响应分析器***等构成。深层网络爬虫表单填写的方式有两类：基于***领域知识***的表单填写和基于***网页结构分析***的表单填写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 重点--聚焦爬虫\n",
    "\n",
    "由于聚集爬虫可以按相应的主题有目的地进行页面（数据）爬取，可以节省大量服务器和带宽资源，具有很强的实用性。\n",
    "聚焦爬虫的工作流程如下图所示：\n",
    "\n",
    "![聚焦爬虫的工作流程](images/crawlflow.jpeg \"聚焦爬虫的工作流程\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. 网络爬虫的用途\n",
    "\n",
    "### 网络爬虫的常用功能\n",
    "\n",
    "网络爬虫的常用功能有：\n",
    "\n",
    "* 搜索引擎\n",
    "* 爬取图片\n",
    "* 爬取网站用户公开的信息进行分析\n",
    "* 爬取金融数据进行投资分析\n",
    "* 爬取多站新闻集中阅读\n",
    "* 自动去网页广告\n",
    "* 爬取用户公开的联系方式，进行营销\n",
    "\n",
    "爬虫的出现，可以在一定程度上代替手工访问网页，使人工访问互联网的操作自动化，以更高效地利用好互联网中的有价值信息。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 搜索引擎核心\n",
    "\n",
    "搜索引擎核心工作流程如下图所示：\n",
    "\n",
    "![搜索引擎核心工作流程](images/seflow.jpeg \"搜索引擎核心工作流程\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用户爬虫\n",
    "\n",
    "用户爬虫即专门用来爬取互联网中用户数据（价值比较高）的一种爬虫。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 网络爬虫实现原理与技术\n",
    "\n",
    "### 网络爬虫实现原理\n",
    "\n",
    "#### 1 通用网络爬虫\n",
    "\n",
    "通用网络爬虫的实现原理及过程如下图所示：\n",
    "\n",
    "![通用网络爬虫的实现原理及过程](images/gpcrawler.jpeg \"通用网络爬虫的实现原理及过程\")\n",
    "\n",
    "#### 2 聚焦网络爬虫\n",
    "\n",
    "聚焦网络爬虫，由于其需要有目的地进行爬取，所以相对于通用网络爬虫，增加了目标定义和过滤机制，也就是说，其执行原理和执行过程需要比通用网络爬虫多出三步，即目标的定义、无关链接的过滤和下一步要爬取URL地址的选取等，如下图所示：\n",
    "\n",
    "![聚焦网络爬虫的基本原理及其实现过程](images/focuscrawler.jpeg \"聚焦网络爬虫的基本原理及其实现过程\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 爬行策略\n",
    "\n",
    "爬行策略主要有**深度优先**、**广度优先**、**大站优先**、**反链策略**等。\n",
    "\n",
    "如下图所示，假设有一个网站，ABCDEFG分别为站点下的网页，图中箭头表示网页的层次结构。\n",
    "\n",
    "![某网站的网页层次结构](images/ia.jpeg \"网页层次结构\")\n",
    "\n",
    "如果按照深度优先爬行策略，则首先会爬取上层的一个网页，然后将此网页的下层链接依次深入爬取完再返回上一层进行爬取。\n",
    "所以，若按照深度优先爬行策略，上图网页的爬行顺序可以是：A -> D -> E -> B -> C -> F -> G\n",
    "\n",
    "如果按照广度优先爬行策略，则首先会爬取同一层次的网页，将同一层次的网页全部爬取完成后，再选择下一个层次的网页去爬行。所以，若按照广度优先爬行策略，上图网页的爬行顺序可以是：A -> B -> C -> D -> E -> F -> G\n",
    "\n",
    "所谓***大站***就是网页数量多的网站。大站优先爬取策略，就是优先爬取大站中网页URL的策略。\n",
    "\n",
    "一个网页的***反向链接***数，指的是该网页被其他网页指向的次数，这反映了该网页被其他网页引用（推荐）的次数。因此，如果按照反链策略爬行的话，将优先爬行受欢迎（当然不一定真实）的网页。\n",
    "\n",
    "除了上述爬行策略，实际中还有很多其他爬行策略，如OPIC（在线页面重要性计算）策略、Partial PageRank（非完全页面分级）策略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更新策略\n",
    "\n",
    "显然，网站的更新频率与爬虫访问网站的频率越接近，效果越好。当爬虫服务器资源有限时，爬虫也需要根据对应策略，让不同的网页具有不同的更新优先级，优先级高的网页更新，将获得较快的爬取响应。\n",
    "\n",
    "具体来说，常见的网页更新策略主要有3种：\n",
    "\n",
    "* **用户体验策略**：优先更新排名结果靠前的网页\n",
    "* **历史数据策略**：通过泊松过程进行建模等手段，预测网页下一次更新的时间，从而确定下一次对该网页爬取的时间，即确定更新周期\n",
    "* **聚类分析策略**：使用聚类算法计算具有类似内容网页的更新频率（内容类似的页面也有类似的更新频率）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网页分析算法\n",
    "\n",
    "网页分析，就是对爬取到原始数据库中的网页进行分析以确定网页重要性，作为用户检索排名结果的依据。\n",
    "\n",
    "搜索引擎的网页分析算法主要分为3类：\n",
    "\n",
    "* **基于用户行为的网页分析算法**：即依据用户对这些网页的访问行为（如访问频率、时长，点击率）对网页进行评价\n",
    "* **基于网络拓扑的网页分析算法**：即依据网页的链接关系、结构关系、已知网页或数据等对网页进行分析的一种算法。所谓拓扑，即结构关系。可以细分为：基于网页粒度（如PageRank）的分析算法；基于网页块粒度的分析算法；基于网站粒度（SiteRank）的分析算法\n",
    "* **基于网页内容的网页分析算法**：即依据网页的数据、文本等网页内容特征，对网页进行相应的评价"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 身份识别\n",
    "\n",
    "一般地，爬虫在对网页进行爬取访问的时候，会通过HTTP请求中的UserAgent字段告知Web服务器自己的身份信息。\n",
    "\n",
    "一般爬虫访问一个网站的时候，首先会根据该站点下的Robots.txt文件来确定可爬取网页的范围。Robots协议是需要网络爬虫遵守的协议，对于一些禁止的URL地址，网络爬虫则不应爬取访问。\n",
    "\n",
    "当然，有些爬虫会伪装成其他爬虫或浏览器去爬取网站，以获得额外数据。虽然在技术上可以无视Robots协议的限制而任意爬取，但这些行为不提倡。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网络爬虫实现技术\n",
    "\n",
    "几乎所以的编程语言和平台都可以实现网络爬虫，常见的有：\n",
    "\n",
    "* Python：框架丰富，简单易学，代码简洁，可读性高\n",
    "* Java：适合大型爬虫项目\n",
    "* PHP：后端处理很强，模块丰富，但不易开发\n",
    "* NodeJS：高并发，多线程\n",
    "* C++：速度快，成本高\n",
    "* Go：高并发"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实验-使用GooSeeker爬取当当图书信息\n",
    "\n",
    "GooSeeker是一款实用的网站数据采集程序，通过使用该工具，可以让大家快速、形象地了解爬虫的工作过程。\n",
    "\n",
    "#### 实验步骤\n",
    "\n",
    "1. 打开[当当网新书栏目](http://e.dangdang.com/morelist_page.html)查看新书名称和价格信息\n",
    "2. 从[GooSeeker官网](http://www.gooseeker.com/pro/product.html)下载并安装GooSeeker网络爬虫\n",
    "3. 参考官网教程使用GooSeeker爬取当当新书栏目网页中的商品名称和商品价格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

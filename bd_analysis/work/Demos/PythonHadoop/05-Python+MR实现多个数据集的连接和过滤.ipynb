{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 Python + MR 实现多个数据集的连接（Join）和过滤\n",
    "---\n",
    "\n",
    "## 实验目的\n",
    "\n",
    "基于MapReduce思想，在Hadoop集群上实现多个数据集的连接。\n",
    "\n",
    "## 实验要求\n",
    "\n",
    "理解MapReduce编程思想，会用Python编写基于HadoopStreaming的MapReduce多数据集连接（Join）程序，然后将其在本地测试并在Hadoop集群上执行并分析执行过程。\n",
    "\n",
    "## 实验内容\n",
    "\n",
    "### 1. 问题描述\n",
    "\n",
    "这里有三个数据集，分别为**学生表**（student.csv），**成绩表**（score.csv）和**优秀学生表**（top.csv），其中**学生表**的每条记录由***学号（id）***和***姓名（name）***字段组成，**成绩表**的每条记录由***学号（id）***，***科目（course）***和***分数（score）***字段组成，**优秀学生表**的只包含了优秀学生的***姓名（name）***字段。\n",
    "\n",
    "现在要将**学生表**和**成绩表**按照学号进行连接，生成学生成绩表，新表包含***学号（id）***、***姓名（name）***、***科目（course）***和***分数（score）***。然后，根据***优秀学生表***从***学生成绩表***中过滤出优秀学生的记录并输出。\n",
    "\n",
    "### 2. 实现原理\n",
    "\n",
    "给每个数据源加上一个数字标记label，这样hadoop对其排序后同一个字段的数据排在一起并且按照label排好序了，于是直接将相邻相同key的数据合并在一起输出就得到了结果。各个阶段的操作如下：\n",
    "1. **map**阶段：分别给表1和表2的记录加标记，其实就是多输出一个标记（label）字段，比如来自表1记录的标记字段的值1，来自表2标记字段的值为2\n",
    "2. **partition**阶段：根据学号key为第一主键，标记字段（label）为第二主键进行排序和分区\n",
    "3. **reduce**阶段：由于已经按照第一主键、第二主键排好了序，将相邻相同key数据合并输出即可\n",
    "\n",
    "## 实验步骤\n",
    "\n",
    "### 1. 准备数据\n",
    "\n",
    "学生表的数据内容如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,name\n",
      "001,Jack\n",
      "002,Marry\n",
      "003,Nacy\n",
      "004,Leion\n",
      "005,Harry\n",
      "006,Tomy\n",
      "007,Sharry\n",
      "008,ZK\n",
      "009,HJ\n",
      "010,MD"
     ]
    }
   ],
   "source": [
    "# 学生表\n",
    "!cat data/student.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,course,score\n",
      "001,Math,80\n",
      "001,Python,90\n",
      "002,Math,82\n",
      "002,Python,95\n",
      "003,Math,80\n",
      "003,Python,95\n",
      "004,Math,96\n",
      "004,Python,85\n",
      "005,Math,78\n",
      "005,Python,82\n",
      "006,Math,100\n",
      "006,Python,100\n",
      "007,Math,72\n",
      "007,Python,75\n",
      "008,Math,100\n",
      "008,Python,100\n",
      "009,Math,100\n",
      "009,Python,100\n",
      "010,Math,98\n",
      "010,Python,98"
     ]
    }
   ],
   "source": [
    "# 成绩表\n",
    "!cat data/score.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name\n",
      "ZK\n",
      "MD\n",
      "HJ\n",
      "Tomy"
     ]
    }
   ],
   "source": [
    "# 优秀学生表\n",
    "!cat data/top_student.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 编写程序\n",
    "\n",
    "#### 1）Mapper（student_score_mapper.py）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/python\n",
      "# -*- coding: utf-8 -*-\n",
      "import sys\n",
      "\n",
      "def main():\n",
      "    for line in sys.stdin:\n",
      "        line = line.strip()\n",
      "        row = line.split(',')\n",
      "        sid = row[0]\n",
      "        if sid == 'sid':\n",
      "            continue\n",
      "        if len(row) == 2:\n",
      "            name = row[1]\n",
      "            course = '-'\n",
      "            score = '-'            \n",
      "        else:\n",
      "            name = '-'\n",
      "            course = row[1]\n",
      "            score = row[2]\n",
      "        print('\\t'.join((sid, course, name, score)))\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    main()"
     ]
    }
   ],
   "source": [
    "# 程序代码\n",
    "!cat input_files/student_score_mapper.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2）Reducer（student_score_reducer.py）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/python\n",
      "# -*- coding: utf-8 -*-\n",
      "import sys\n",
      "\n",
      "def main():\n",
      "    sname = None\n",
      "    for line in sys.stdin:\n",
      "        line = line.strip()\n",
      "        row = line.split('\\t')\n",
      "        name = row[2]\n",
      "        if name == '-':\n",
      "            row[2] = sname\n",
      "            print('\\t'.join([row[0], row[2], row[1], row[3]]))\n",
      "        else:\n",
      "            sname = name\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    main()"
     ]
    }
   ],
   "source": [
    "# 程序代码\n",
    "!cat input_files/student_score_reducer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 本地测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001,Jack\n",
      "002,Marry\n",
      "003,Nacy\n",
      "004,Leion\n",
      "005,Harry\n",
      "006,Tomy\n",
      "007,Sharry\n",
      "008,ZK\n",
      "009,HJ\n",
      "010,MD\n",
      "001,Math,80\n",
      "001,Python,90\n",
      "002,Math,82\n",
      "002,Python,95\n",
      "003,Math,80\n",
      "003,Python,95\n",
      "004,Math,96\n",
      "004,Python,85\n",
      "005,Math,78\n",
      "005,Python,82\n",
      "006,Math,100\n",
      "006,Python,100\n",
      "007,Math,72\n",
      "007,Python,75\n",
      "008,Math,100\n",
      "008,Python,100\n",
      "009,Math,100\n",
      "009,Python,100\n",
      "010,Math,98\n",
      "010,Python,98\n"
     ]
    }
   ],
   "source": [
    "# 操作代码\n",
    "!cat data/student.csv data/score.csv | \\\n",
    "python input_files/student_score_mapper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001\tJack\tJava\t80\n",
      "001\tJack\tMath\t80\n",
      "001\tJack\tPython\t90\n",
      "002\tMarry\tMath\t82\n",
      "002\tMarry\tPython\t95\n",
      "003\tNacy\tMath\t80\n",
      "003\tNacy\tPython\t95\n",
      "004\tLeion\tMath\t96\n",
      "004\tLeion\tPython\t85\n",
      "005\tHarry\tMath\t78\n",
      "005\tHarry\tPython\t82\n",
      "006\tTomy\tMath\t100\n",
      "006\tTomy\tPython\t100\n",
      "007\tSharry\tMath\t72\n",
      "007\tSharry\tPHP\t69\n",
      "007\tSharry\tPython\t75\n",
      "008\tZK\tMath\t100\n",
      "008\tZK\tPython\t100\n",
      "009\tHJ\tMath\t100\n",
      "009\tHJ\tPython\t100\n",
      "010\tMD\tMath\t98\n",
      "010\tMD\tPython\t98\n"
     ]
    }
   ],
   "source": [
    "# 操作代码\n",
    "!cat data/student.csv data/score.csv | \\\n",
    "python input_files/student_score_mapper.py | \\\n",
    "sort | \\\n",
    "python input_files/student_score_reducer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 集群运行\n",
    "\n",
    "#### 1）上传数据文件到HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 操作代码\n",
    "!docker cp ./data/student.csv master:/root/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker cp ./data/score.csv master:/root/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker cp input_files/student_score_mapper.py master:/root/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker cp input_files/student_score_reducer.py master:/root/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker exec master \\\n",
    "hadoop fs -put /root/student.csv /input/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker exec master \\\n",
    "hadoop fs -put /root/score.csv /input/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2）设置Streaming参数并执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/08/14 11:10:54 INFO Configuration.deprecation: io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum\n",
      "Deleted /output/student_score\n",
      "19/08/14 11:10:56 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
      "packageJobJar: [/root/student_score_mapper.py, /root/student_score_reducer.py] [] /tmp/streamjob7335127436191596496.jar tmpDir=null\n",
      "19/08/14 11:10:57 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "19/08/14 11:10:57 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "19/08/14 11:10:58 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "19/08/14 11:10:58 INFO mapred.FileInputFormat: Total input files to process : 2\n",
      "19/08/14 11:10:58 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "19/08/14 11:10:58 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "19/08/14 11:10:58 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name\n",
      "19/08/14 11:10:58 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "19/08/14 11:10:58 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1435117397_0001\n",
      "19/08/14 11:10:59 INFO mapred.LocalDistributedCacheManager: Localized file:/root/student_score_mapper.py as file:/tmp/hadoop-root/mapred/local/1565781059037/student_score_mapper.py\n",
      "19/08/14 11:10:59 INFO mapred.LocalDistributedCacheManager: Localized file:/root/student_score_reducer.py as file:/tmp/hadoop-root/mapred/local/1565781059038/student_score_reducer.py\n",
      "19/08/14 11:10:59 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
      "19/08/14 11:10:59 INFO mapreduce.Job: Running job: job_local1435117397_0001\n",
      "19/08/14 11:10:59 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
      "19/08/14 11:10:59 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n",
      "19/08/14 11:10:59 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "19/08/14 11:10:59 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "19/08/14 11:10:59 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
      "19/08/14 11:10:59 INFO mapred.LocalJobRunner: Starting task: attempt_local1435117397_0001_m_000000_0\n",
      "19/08/14 11:10:59 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "19/08/14 11:10:59 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "19/08/14 11:10:59 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "19/08/14 11:10:59 INFO mapred.MapTask: Processing split: file:/input/score.csv:0+306\n",
      "19/08/14 11:10:59 INFO mapred.MapTask: numReduceTasks: 1\n",
      "19/08/14 11:10:59 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "19/08/14 11:10:59 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "19/08/14 11:10:59 INFO mapred.MapTask: soft limit at 83886080\n",
      "19/08/14 11:10:59 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "19/08/14 11:10:59 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "19/08/14 11:10:59 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "19/08/14 11:10:59 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/spark-2.3.0/./student_score_mapper.py]\n",
      "19/08/14 11:10:59 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n",
      "19/08/14 11:10:59 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n",
      "19/08/14 11:10:59 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n",
      "19/08/14 11:10:59 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "19/08/14 11:10:59 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n",
      "19/08/14 11:10:59 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n",
      "19/08/14 11:10:59 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n",
      "19/08/14 11:10:59 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "19/08/14 11:10:59 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n",
      "19/08/14 11:10:59 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
      "19/08/14 11:10:59 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "19/08/14 11:10:59 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n",
      "19/08/14 11:10:59 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "19/08/14 11:10:59 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "19/08/14 11:10:59 INFO streaming.PipeMapRed: Records R/W=23/1\n",
      "19/08/14 11:10:59 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "19/08/14 11:10:59 INFO streaming.PipeMapRed: mapRedFinished\n",
      "19/08/14 11:10:59 INFO mapred.LocalJobRunner: \n",
      "19/08/14 11:10:59 INFO mapred.MapTask: Starting flush of map output\n",
      "19/08/14 11:10:59 INFO mapred.MapTask: Spilling map output\n",
      "19/08/14 11:10:59 INFO mapred.MapTask: bufstart = 0; bufend = 333; bufvoid = 104857600\n",
      "19/08/14 11:10:59 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214312(104857248); length = 85/6553600\n",
      "19/08/14 11:10:59 INFO mapred.MapTask: Finished spill 0\n",
      "19/08/14 11:10:59 INFO mapred.Task: Task:attempt_local1435117397_0001_m_000000_0 is done. And is in the process of committing\n",
      "19/08/14 11:10:59 INFO mapred.LocalJobRunner: Records R/W=23/1\n",
      "19/08/14 11:10:59 INFO mapred.Task: Task 'attempt_local1435117397_0001_m_000000_0' done.\n",
      "19/08/14 11:10:59 INFO mapred.Task: Final Counters for attempt_local1435117397_0001_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=2190\n",
      "\t\tFILE: Number of bytes written=378007\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=23\n",
      "\t\tMap output records=22\n",
      "\t\tMap output bytes=333\n",
      "\t\tMap output materialized bytes=383\n",
      "\t\tInput split bytes=73\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=22\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=189267968\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=322\n",
      "19/08/14 11:10:59 INFO mapred.LocalJobRunner: Finishing task: attempt_local1435117397_0001_m_000000_0\n",
      "19/08/14 11:10:59 INFO mapred.LocalJobRunner: Starting task: attempt_local1435117397_0001_m_000001_0\n",
      "19/08/14 11:11:00 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "19/08/14 11:11:00 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "19/08/14 11:11:00 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "19/08/14 11:11:00 INFO mapred.MapTask: Processing split: file:/input/student.csv:0+98\n",
      "19/08/14 11:11:00 INFO mapred.MapTask: numReduceTasks: 1\n",
      "19/08/14 11:11:00 INFO mapreduce.Job: Job job_local1435117397_0001 running in uber mode : false\n",
      "19/08/14 11:11:00 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "19/08/14 11:11:00 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "19/08/14 11:11:00 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "19/08/14 11:11:00 INFO mapred.MapTask: soft limit at 83886080\n",
      "19/08/14 11:11:00 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "19/08/14 11:11:00 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "19/08/14 11:11:00 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "19/08/14 11:11:00 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/spark-2.3.0/./student_score_mapper.py]\n",
      "19/08/14 11:11:00 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "19/08/14 11:11:00 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "19/08/14 11:11:00 INFO streaming.PipeMapRed: Records R/W=11/1\n",
      "19/08/14 11:11:00 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "19/08/14 11:11:00 INFO streaming.PipeMapRed: mapRedFinished\n",
      "19/08/14 11:11:00 INFO mapred.LocalJobRunner: \n",
      "19/08/14 11:11:00 INFO mapred.MapTask: Starting flush of map output\n",
      "19/08/14 11:11:00 INFO mapred.MapTask: Spilling map output\n",
      "19/08/14 11:11:00 INFO mapred.MapTask: bufstart = 0; bufend = 129; bufvoid = 104857600\n",
      "19/08/14 11:11:00 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214360(104857440); length = 37/6553600\n",
      "19/08/14 11:11:00 INFO mapred.MapTask: Finished spill 0\n",
      "19/08/14 11:11:00 INFO mapred.Task: Task:attempt_local1435117397_0001_m_000001_0 is done. And is in the process of committing\n",
      "19/08/14 11:11:00 INFO mapred.LocalJobRunner: Records R/W=11/1\n",
      "19/08/14 11:11:00 INFO mapred.Task: Task 'attempt_local1435117397_0001_m_000001_0' done.\n",
      "19/08/14 11:11:00 INFO mapred.Task: Final Counters for attempt_local1435117397_0001_m_000001_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=2471\n",
      "\t\tFILE: Number of bytes written=378194\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=11\n",
      "\t\tMap output records=10\n",
      "\t\tMap output bytes=129\n",
      "\t\tMap output materialized bytes=155\n",
      "\t\tInput split bytes=75\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=10\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=294649856\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=114\n",
      "19/08/14 11:11:00 INFO mapred.LocalJobRunner: Finishing task: attempt_local1435117397_0001_m_000001_0\n",
      "19/08/14 11:11:00 INFO mapred.LocalJobRunner: map task executor complete.\n",
      "19/08/14 11:11:00 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
      "19/08/14 11:11:00 INFO mapred.LocalJobRunner: Starting task: attempt_local1435117397_0001_r_000000_0\n",
      "19/08/14 11:11:00 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "19/08/14 11:11:00 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "19/08/14 11:11:00 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "19/08/14 11:11:00 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2e6a2948\n",
      "19/08/14 11:11:00 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "19/08/14 11:11:00 INFO reduce.EventFetcher: attempt_local1435117397_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "19/08/14 11:11:01 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1435117397_0001_m_000001_0 decomp: 151 len: 155 to MEMORY\n",
      "19/08/14 11:11:01 INFO reduce.InMemoryMapOutput: Read 151 bytes from map-output for attempt_local1435117397_0001_m_000001_0\n",
      "19/08/14 11:11:01 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 151, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->151\n",
      "19/08/14 11:11:01 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1435117397_0001_m_000000_0 decomp: 379 len: 383 to MEMORY\n",
      "19/08/14 11:11:01 INFO reduce.InMemoryMapOutput: Read 379 bytes from map-output for attempt_local1435117397_0001_m_000000_0\n",
      "19/08/14 11:11:01 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 379, inMemoryMapOutputs.size() -> 2, commitMemory -> 151, usedMemory ->530\n",
      "19/08/14 11:11:01 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
      "19/08/14 11:11:01 INFO mapred.LocalJobRunner: 2 / 2 copied.\n",
      "19/08/14 11:11:01 INFO reduce.MergeManagerImpl: finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs\n",
      "19/08/14 11:11:01 INFO mapred.Merger: Merging 2 sorted segments\n",
      "19/08/14 11:11:01 INFO mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 504 bytes\n",
      "19/08/14 11:11:01 INFO reduce.MergeManagerImpl: Merged 2 segments, 530 bytes to disk to satisfy reduce memory limit\n",
      "19/08/14 11:11:01 INFO reduce.MergeManagerImpl: Merging 1 files, 532 bytes from disk\n",
      "19/08/14 11:11:01 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
      "19/08/14 11:11:01 INFO mapred.Merger: Merging 1 sorted segments\n",
      "19/08/14 11:11:01 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 515 bytes\n",
      "19/08/14 11:11:01 INFO mapred.LocalJobRunner: 2 / 2 copied.\n",
      "19/08/14 11:11:01 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/spark-2.3.0/./student_score_reducer.py]\n",
      "19/08/14 11:11:01 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "19/08/14 11:11:01 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "19/08/14 11:11:01 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "19/08/14 11:11:01 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "19/08/14 11:11:01 INFO streaming.PipeMapRed: Records R/W=32/1\n",
      "19/08/14 11:11:01 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "19/08/14 11:11:01 INFO streaming.PipeMapRed: mapRedFinished\n",
      "19/08/14 11:11:01 INFO mapred.Task: Task:attempt_local1435117397_0001_r_000000_0 is done. And is in the process of committing\n",
      "19/08/14 11:11:01 INFO mapred.LocalJobRunner: 2 / 2 copied.\n",
      "19/08/14 11:11:01 INFO mapred.Task: Task attempt_local1435117397_0001_r_000000_0 is allowed to commit now\n",
      "19/08/14 11:11:01 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1435117397_0001_r_000000_0' to file:/output/student_score/_temporary/0/task_local1435117397_0001_r_000000\n",
      "19/08/14 11:11:01 INFO mapred.LocalJobRunner: Records R/W=32/1 > reduce\n",
      "19/08/14 11:11:01 INFO mapred.Task: Task 'attempt_local1435117397_0001_r_000000_0' done.\n",
      "19/08/14 11:11:01 INFO mapred.Task: Final Counters for attempt_local1435117397_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=3605\n",
      "\t\tFILE: Number of bytes written=379137\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=32\n",
      "\t\tReduce shuffle bytes=538\n",
      "\t\tReduce input records=32\n",
      "\t\tReduce output records=22\n",
      "\t\tSpilled Records=32\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=294649856\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=411\n",
      "19/08/14 11:11:01 INFO mapred.LocalJobRunner: Finishing task: attempt_local1435117397_0001_r_000000_0\n",
      "19/08/14 11:11:01 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
      "19/08/14 11:11:01 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "19/08/14 11:11:01 INFO mapreduce.Job: Job job_local1435117397_0001 completed successfully\n",
      "19/08/14 11:11:01 INFO mapreduce.Job: Counters: 30\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=8266\n",
      "\t\tFILE: Number of bytes written=1135338\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=34\n",
      "\t\tMap output records=32\n",
      "\t\tMap output bytes=462\n",
      "\t\tMap output materialized bytes=538\n",
      "\t\tInput split bytes=148\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=32\n",
      "\t\tReduce shuffle bytes=538\n",
      "\t\tReduce input records=32\n",
      "\t\tReduce output records=22\n",
      "\t\tSpilled Records=64\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=778567680\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=436\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=411\n",
      "19/08/14 11:11:01 INFO streaming.StreamJob: Output directory: /output/student_score\n"
     ]
    }
   ],
   "source": [
    "# 操作代码\n",
    "!docker exec master \\\n",
    "hadoop fs -rm -f -r /output/student_score\n",
    "!docker exec master \\\n",
    "hadoop jar /usr/hadoop-2.8.3/share/hadoop/tools/lib/hadoop-streaming-2.8.3.jar \\\n",
    "-D stream.num.map.output.key.fields=3 \\\n",
    "-D num.key.fields.for.partition=1 \\\n",
    "-D mapred.map.tasks=10 \\\n",
    "-D mapred.reduce.tasks=1 \\\n",
    "-D mapred.job.name=\"Student_Score_Join\" \\\n",
    "-partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner \\\n",
    "-input /input/student.csv \\\n",
    "-input /input/score.csv \\\n",
    "-output /output/student_score \\\n",
    "-mapper /root/student_score_mapper.py \\\n",
    "-reducer /root/student_score_reducer.py \\\n",
    "-file /root/student_score_mapper.py \\\n",
    "-file /root/student_score_reducer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3）查看结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   1 root root          0 2019-08-14 11:11 /output/student_score/_SUCCESS\n",
      "-rw-r--r--   1 root root        399 2019-08-14 11:11 /output/student_score/part-00000\n"
     ]
    }
   ],
   "source": [
    "# 操作代码\n",
    "!docker exec master \\\n",
    "hadoop fs -ls /output/student_score/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001\tJack\tJava\t80\n",
      "001\tJack\tMath\t80\n",
      "001\tJack\tPython\t90\n",
      "002\tMarry\tMath\t82\n",
      "002\tMarry\tPython\t95\n",
      "003\tNacy\tMath\t80\n",
      "003\tNacy\tPython\t95\n",
      "004\tLeion\tMath\t96\n",
      "004\tLeion\tPython\t85\n",
      "005\tHarry\tMath\t78\n",
      "005\tHarry\tPython\t82\n",
      "006\tTomy\tMath\t100\n",
      "006\tTomy\tPython\t100\n",
      "007\tSharry\tMath\t72\n",
      "007\tSharry\tPHP\t69\n",
      "007\tSharry\tPython\t75\n",
      "008\tZK\tMath\t100\n",
      "008\tZK\tPython\t100\n",
      "009\tHJ\tMath\t100\n",
      "009\tHJ\tPython\t100\n",
      "010\tMD\tMath\t98\n",
      "010\tMD\tPython\t98\n"
     ]
    }
   ],
   "source": [
    "!docker exec master \\\n",
    "hadoop fs -cat /output/student_score/part-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 离线分析\n",
    "\n",
    "#### 1）下载数据到本地"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker exec master \\\n",
    "hadoop fs -get /output/student_score/part-00000 \\\n",
    "/root/student_score_result.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker cp master:/root/student_score_result.txt ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo 'id\\tname\\tcourse\\tscore' > ./data/student_score.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat data/student_score_result.txt >> ./data/student_score.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2）处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/student_score.csv', sep='\\t')\n",
    "g = df.groupby('id')\n",
    "r = g.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3）可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11e3b9438>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 程序代码\n",
    "r.plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                            Version \n",
      "---------------------------------- --------\n",
      "alabaster                          0.7.12  \n",
      "anaconda-client                    1.7.2   \n",
      "anaconda-navigator                 1.9.7   \n",
      "anaconda-project                   0.8.2   \n",
      "appnope                            0.1.0   \n",
      "appscript                          1.0.1   \n",
      "asn1crypto                         0.24.0  \n",
      "astroid                            2.2.5   \n",
      "astropy                            3.1.2   \n",
      "atomicwrites                       1.3.0   \n",
      "attrs                              19.1.0  \n",
      "Automat                            0.7.0   \n",
      "Babel                              2.6.0   \n",
      "backcall                           0.1.0   \n",
      "backports.os                       0.1.1   \n",
      "backports.shutil-get-terminal-size 1.0.0   \n",
      "beautifulsoup4                     4.7.1   \n",
      "bitarray                           0.8.3   \n",
      "bkcharts                           0.2     \n",
      "bleach                             3.1.0   \n",
      "bokeh                              1.0.4   \n",
      "boto                               2.49.0  \n",
      "Bottleneck                         1.2.1   \n",
      "certifi                            2019.3.9\n",
      "cffi                               1.12.2  \n",
      "chardet                            3.0.4   \n",
      "Click                              7.0     \n",
      "cloudpickle                        0.8.0   \n",
      "clyent                             1.2.2   \n",
      "colorama                           0.4.1   \n",
      "conda                              4.6.11  \n",
      "conda-build                        3.17.8  \n",
      "conda-verify                       3.1.1   \n",
      "constantly                         15.1.0  \n",
      "contextlib2                        0.5.5   \n",
      "cryptography                       2.6.1   \n",
      "cssselect                          1.0.3   \n",
      "cycler                             0.10.0  \n",
      "Cython                             0.29.6  \n",
      "cytoolz                            0.9.0.1 \n",
      "dask                               1.1.4   \n",
      "decorator                          4.4.0   \n",
      "defusedxml                         0.5.0   \n",
      "distributed                        1.26.0  \n",
      "docutils                           0.14    \n",
      "entrypoints                        0.3     \n",
      "et-xmlfile                         1.0.1   \n",
      "fastcache                          1.0.2   \n",
      "filelock                           3.0.10  \n",
      "Flask                              1.0.2   \n",
      "future                             0.17.1  \n",
      "gevent                             1.4.0   \n",
      "glob2                              0.6     \n",
      "gmpy2                              2.0.8   \n",
      "greenlet                           0.4.15  \n",
      "h5py                               2.9.0   \n",
      "heapdict                           1.0.0   \n",
      "html5lib                           1.0.1   \n",
      "hyperlink                          19.0.0  \n",
      "idna                               2.8     \n",
      "imageio                            2.5.0   \n",
      "imagesize                          1.1.0   \n",
      "importlib-metadata                 0.0.0   \n",
      "incremental                        17.5.0  \n",
      "ipykernel                          5.1.0   \n",
      "ipython                            7.4.0   \n",
      "ipython-genutils                   0.2.0   \n",
      "ipywidgets                         7.4.2   \n",
      "isort                              4.3.16  \n",
      "itsdangerous                       1.1.0   \n",
      "jdcal                              1.4     \n",
      "jedi                               0.13.3  \n",
      "Jinja2                             2.10    \n",
      "jsonschema                         3.0.1   \n",
      "jupyter                            1.0.0   \n",
      "jupyter-client                     5.2.4   \n",
      "jupyter-console                    6.0.0   \n",
      "jupyter-core                       4.4.0   \n",
      "jupyterlab                         0.35.4  \n",
      "jupyterlab-server                  0.2.0   \n",
      "keyring                            18.0.0  \n",
      "kiwisolver                         1.0.1   \n",
      "lazy-object-proxy                  1.3.1   \n",
      "libarchive-c                       2.8     \n",
      "lief                               0.9.0   \n",
      "llvmlite                           0.28.0  \n",
      "locket                             0.2.0   \n",
      "lxml                               4.3.2   \n",
      "MarkupSafe                         1.1.1   \n",
      "matplotlib                         3.0.3   \n",
      "mccabe                             0.6.1   \n",
      "mistune                            0.8.4   \n",
      "mkl-fft                            1.0.10  \n",
      "mkl-random                         1.0.2   \n",
      "more-itertools                     6.0.0   \n",
      "mpmath                             1.1.0   \n",
      "msgpack                            0.6.1   \n",
      "multipledispatch                   0.6.0   \n",
      "navigator-updater                  0.2.1   \n",
      "nbconvert                          5.4.1   \n",
      "nbformat                           4.4.0   \n",
      "networkx                           2.2     \n",
      "nltk                               3.4     \n",
      "nose                               1.3.7   \n",
      "notebook                           5.7.8   \n",
      "numba                              0.43.1  \n",
      "numexpr                            2.6.9   \n",
      "numpy                              1.16.2  \n",
      "numpydoc                           0.8.0   \n",
      "olefile                            0.46    \n",
      "openpyxl                           2.6.1   \n",
      "packaging                          19.0    \n",
      "pandas                             0.24.2  \n",
      "pandocfilters                      1.4.2   \n",
      "parsel                             1.5.1   \n",
      "parso                              0.3.4   \n",
      "partd                              0.3.10  \n",
      "path.py                            11.5.0  \n",
      "pathlib2                           2.3.3   \n",
      "patsy                              0.5.1   \n",
      "pep8                               1.7.1   \n",
      "pexpect                            4.6.0   \n",
      "pickleshare                        0.7.5   \n",
      "Pillow                             5.4.1   \n",
      "pip                                19.0.3  \n",
      "pkginfo                            1.5.0.1 \n",
      "pluggy                             0.9.0   \n",
      "ply                                3.11    \n",
      "prettytable                        0.7.2   \n",
      "prometheus-client                  0.6.0   \n",
      "prompt-toolkit                     2.0.9   \n",
      "psutil                             5.6.1   \n",
      "ptyprocess                         0.6.0   \n",
      "py                                 1.8.0   \n",
      "pyasn1                             0.4.6   \n",
      "pyasn1-modules                     0.2.6   \n",
      "pycodestyle                        2.5.0   \n",
      "pycosat                            0.6.3   \n",
      "pycparser                          2.19    \n",
      "pycrypto                           2.6.1   \n",
      "pycurl                             7.43.0.2\n",
      "PyDispatcher                       2.0.5   \n",
      "pyecharts                          1.3.1   \n",
      "pyflakes                           2.1.1   \n",
      "Pygments                           2.3.1   \n",
      "PyHamcrest                         1.9.0   \n",
      "pylint                             2.3.1   \n",
      "pyodbc                             4.0.26  \n",
      "pyOpenSSL                          19.0.0  \n",
      "pyparsing                          2.3.1   \n",
      "pyrsistent                         0.14.11 \n",
      "PySocks                            1.6.8   \n",
      "pytest                             4.3.1   \n",
      "pytest-arraydiff                   0.3     \n",
      "pytest-astropy                     0.5.0   \n",
      "pytest-doctestplus                 0.3.0   \n",
      "pytest-openfiles                   0.3.2   \n",
      "pytest-remotedata                  0.3.1   \n",
      "python-dateutil                    2.8.0   \n",
      "pytz                               2018.9  \n",
      "PyWavelets                         1.0.2   \n",
      "PyYAML                             5.1     \n",
      "pyzmq                              18.0.0  \n",
      "QtAwesome                          0.5.7   \n",
      "qtconsole                          4.4.3   \n",
      "QtPy                               1.7.0   \n",
      "queuelib                           1.5.0   \n",
      "requests                           2.21.0  \n",
      "rope                               0.12.0  \n",
      "ruamel-yaml                        0.15.46 \n",
      "scikit-image                       0.14.2  \n",
      "scikit-learn                       0.20.3  \n",
      "scipy                              1.2.1   \n",
      "Scrapy                             1.7.3   \n",
      "seaborn                            0.9.0   \n",
      "selenium                           3.141.0 \n",
      "Send2Trash                         1.5.0   \n",
      "service-identity                   18.1.0  \n",
      "setuptools                         40.8.0  \n",
      "simplegeneric                      0.8.1   \n",
      "simplejson                         3.16.0  \n",
      "singledispatch                     3.4.0.3 \n",
      "six                                1.12.0  \n",
      "snowballstemmer                    1.2.1   \n",
      "sortedcollections                  1.1.2   \n",
      "sortedcontainers                   2.1.0   \n",
      "soupsieve                          1.8     \n",
      "Sphinx                             1.8.5   \n",
      "sphinxcontrib-websupport           1.1.0   \n",
      "spyder                             3.3.3   \n",
      "spyder-kernels                     0.4.2   \n",
      "SQLAlchemy                         1.3.1   \n",
      "statsmodels                        0.9.0   \n",
      "sympy                              1.3     \n",
      "tables                             3.5.1   \n",
      "tblib                              1.3.2   \n",
      "terminado                          0.8.1   \n",
      "testpath                           0.4.2   \n",
      "toolz                              0.9.0   \n",
      "tornado                            6.0.2   \n",
      "tqdm                               4.31.1  \n",
      "traitlets                          4.3.2   \n",
      "Twisted                            19.7.0  \n",
      "unicodecsv                         0.14.1  \n",
      "urllib3                            1.24.1  \n",
      "w3lib                              1.20.0  \n",
      "wcwidth                            0.1.7   \n",
      "webencodings                       0.5.1   \n",
      "Werkzeug                           0.14.1  \n",
      "wheel                              0.33.1  \n",
      "widgetsnbextension                 3.4.2   \n",
      "wrapt                              1.11.1  \n",
      "wurlitzer                          1.0.2   \n",
      "xlrd                               1.2.0   \n",
      "XlsxWriter                         1.1.5   \n",
      "xlwings                            0.15.4  \n",
      "xlwt                               1.3.0   \n",
      "zict                               0.1.4   \n",
      "zipp                               0.3.3   \n",
      "zope.interface                     4.6.0   \n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 过程分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- 文字内容 ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 心得体会"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- 文字内容 ---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
